# -*- coding: utf-8 -*-
"""functs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TOak2cxtK3OI-M1yU9JdVUOk9lvQw-f9
"""

# All helper functions used in final notebook

# general imports
import numpy as np
import pandas as pd
import tensorflow as tf
import re
import string

# tensorflow model imports
from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow import keras

# sklearn modeling imports
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# visualization imports
import seaborn as sns
from matplotlib import pyplot as plt

def combine_delq(df):
  """
  This function takes a dataframe input, and then adds a delinquency column labeling delq loans
  """
  # creates a new column in the dataframe checking if loan is delq
  df['Delq']=df.loan_status.apply(lambda x: 0 if "DELQ" in x else 1)
  # 0 if delinquent, 1 if not

def merge_delq_columns(df):
  """
  this function takes a dataframe input, and merges the two delq columns into one
  """
  df["decDelq"] = df["decDelq"].fillna(2)
  df['decDelq'] = df['decDelq'].astype(int)
  df["Delq"] = np.minimum(df["Delq"], df["decDelq"]) # takes the min of the two values
  df.drop(columns =["decDelq"], inplace = True) # drops unneeded extra column

def clean_data_for_ml(df):
  """
  this function takes a dataframe as an input and cleans the data
  drops untrainable columns and converts all categorical variables into numerical
  """
  df.drop(columns = ["cutoff_date",
                     "loan_id",
                     "loan_group",
                     "delinquent_dt",
                     "days_delinquent",
                     "loan_status"], inplace=True)
  #df = df.dropna()
  le = LabelEncoder()
  for column in df.columns:
    if type(df[column][0]) == str:
      df[column] = le.fit_transform(df[column]) # label encodes all str variables

def traintest(df):
  """
  this function takes a dataframe input, and returns X_train/test and y_train/test vars for keras model
  It performs some of the data preparation, such as splitting the feature and target columns, and normalizing values
  """
  to_train = df[df['Delq'].isin([0,1])]
  to_pred = df[df['Delq'] == 2]

  X = to_train.drop('Delq', axis=1).values
  y = to_train['Delq'].values

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 101)

  scaler = sklearn.preprocessing.MinMaxScaler()
  X_train = scaler.fit_transform(X_train)
  X_test = scaler.transform(X_test)

  return X_train, X_test, y_train, y_test

def delq_count_bar(df):
  """
  this function creates a bar graph visualization of the counts of each class for
  the inputted dataframe
  """
  sns.set_style('darkgrid')
  bar=sns.countplot(x='Delq', data=df)
  bar.set_xlabel('Delinquent?')
  bar.set_ylabel('Count')
  bar.set_title('Delinquency Count')
  bar.set_ylim(-1,90000)

def history_graph(history, metric):
  """
  this function creates a line plot visualization of the inputted model's history
  of the stored metric values over time during it's training
  """
  met = history.history[metric]
  val_met = history.history["val_"+ metric]
  plt.plot(range(20), met, label=f'Training {metric}')
  plt.plot(range(20), val_met, label=f'Validation {metric}')
  plt.legend(loc='lower right')
  plt.title(f'Training and Validation {metric}')

def categorize_credit_score(df,credit_column):
  """
  This function takes a dataframe input, as well as a column name for categorizing
  credit score in a meaningful way
  """
  conditions =[(df[credit_column]>=800),
            (df[credit_column]<800) &(df[credit_column]>=740),
            (df[credit_column]<740) &(df[credit_column]>=670),
            (df[credit_column]<670) &(df[credit_column]>=580),
            (df[credit_column]<580) &(df[credit_column]>=300)]
  values=['Excellent','Very good','Good','Fair','Poor']
  df['credit_score_category']=np.select(conditions, values)

def sort_alph(df,column_name):
  """
  this is a simple function that takes a dataframe and column name input and
  sorts the dataframe by the given column, returning a sorted df
  """
  return df.sort_values(by=[column_name])

